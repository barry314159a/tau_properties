{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1cc2b9-164a-49b9-b1d8-884c2c3b7ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, -24], [2, 252], [3, 4830], [4, -16744], [5, 534612], [6, -577738], [7, -6905934], [8, 10661420], [9, 18643272]]\n",
      "\n",
      "[(0, 2), (1, -24), (2, -72), (3, 18810), (4, 518528), (5, 10323516), (6, 34401720), (7, -3989135538), (8, -155766935712), (9, -2992865260284)]\n"
     ]
    }
   ],
   "source": [
    "# most of this cell's code was run in notebook 'primeTau1oct25no2'\n",
    "from sage.all import sigma, nth_prime\n",
    "from sage.arith.all import moebius\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "# from 'c=1 deformed primetau 26oct25'\n",
    "with open('/Users/barrybrent/data/run26oct25no1.txt', 'rb') as rfile:\n",
    "    tau_prime_list = pickle.load(rfile)\n",
    "h_list=[[0,1]]+tau_prime_list \n",
    "j_list=[(0,2)] #<<< c=2\n",
    "for n in [1..500]:# so j(1) = 1 = h(0) as required.\n",
    "    sm=0\n",
    "    for r in [1..n-1]: \n",
    "        sm=sm+j_list[r][1]*h_list[n-r][1] \n",
    "    j_n=n*h_list[n][1]-sm\n",
    "    j_list.append((n,j_n))\n",
    "\n",
    "print(h_list[:10])\n",
    "print()\n",
    "print(j_list[:10])\n",
    "    \n",
    "with open('/Users/barrybrent/data/run5nov25no2.txt', 'wb') as wfile:\n",
    "    pickle.dump(j_list, wfile) # ouput snipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659db72-31db-4f62-9d16-7c72087f9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sage.all import sigma, nth_prime\n",
    "import ast\n",
    "import time\n",
    "\n",
    "# Increase PARI stack size to handle large polynomial root computations\n",
    "pari.allocatemem(7*10^9)  # Allocate 7GB for PARI stack\n",
    "\n",
    "def tau(n):\n",
    "    def step1(n, k):\n",
    "        return 35*k^4 - 52*k^3*n + 18*k^2*n^2\n",
    "    def step2(n, k):\n",
    "        return sigma(k) * sigma(n - k)\n",
    "    def step3(n):\n",
    "        ans = 0\n",
    "        for k in range(1, n):\n",
    "            ans += step1(n, k) * step2(n, k)\n",
    "        return 24*ans\n",
    "    return n^4 * sigma(n) - step3(n)\n",
    "\n",
    "def h(n):\n",
    "    if n>0:\n",
    "        return tau(n) # i.e., tauPrime(n)\n",
    "    if n==0:\n",
    "        return 1\n",
    "\n",
    "h_list=[h(n) for n in range(0,302)]\n",
    "with open('/Users/barrybrent/data/run5nov25no2.txt', 'rb') as rfile:\n",
    "    j_list = pickle.load(rfile) \n",
    "    \n",
    "def P_matrix(lst):\n",
    "    lenlist=len(lst)\n",
    "    columns=[lst]\n",
    "    for k in range(1,lenlist):\n",
    "        column=[0]*(k-1)\n",
    "        column=column+[-k]\n",
    "        column=flatten(column+[lst])\n",
    "        column=column+[lst]\n",
    "        column=column[:lenlist]\n",
    "        columns+=[column]\n",
    "    return (matrix(columns)).transpose()\n",
    "\n",
    "def periodic_behavior_score(main_local_minima_list, min_score=0.3, max_period=100):\n",
    "    \"\"\"\n",
    "    Analyzes periodic behavior for all v values in main_local_minima_list.\n",
    "    Uses autocorrelation and FFT to detect ANY periodic pattern (not just sine waves).\n",
    "    Filters out results with weak periodicity or unreasonably large periods.\n",
    "    \n",
    "    Args:\n",
    "        main_local_minima_list: List of tuples [(v1, points1), (v2, points2), ...]\n",
    "                                where points are [(x1, y1), (x2, y2), ...]\n",
    "        min_score: Minimum periodicity score to accept (default: 0.3)\n",
    "        max_period: Maximum allowed period (default: 100). Results with larger periods are rejected.\n",
    "    \n",
    "    Returns:\n",
    "        results: List of tuples [(v, score, info_dict), ...] for valid results only\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    rejected = []\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"PERIODIC BEHAVIOR ANALYSIS RESULTS\")\n",
    "    print(f\"(Rejecting: score < {min_score} or period > {max_period})\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for points in mins_list:\n",
    "        if len(points) < 4:\n",
    "            continue\n",
    "        \n",
    "        # Extract x and y coordinates, converting to plain floats\n",
    "        x_data = np.array([float(p[0]) for p in points])\n",
    "        y_data = np.array([float(p[1]) for p in points])\n",
    "        \n",
    "        # Remove mean (detrend)\n",
    "        y_detrended = y_data - np.mean(y_data)\n",
    "        \n",
    "        # --- Method 1: Autocorrelation Analysis ---\n",
    "        autocorr = correlate(y_detrended, y_detrended, mode='full')\n",
    "        autocorr = autocorr[len(autocorr)//2:]\n",
    "        autocorr = autocorr / autocorr[0]  # Normalize\n",
    "        \n",
    "        # Find peaks in autocorrelation (excluding the first peak at lag=0)\n",
    "        peaks, properties = find_peaks(autocorr[1:], prominence=0.1, distance=3)\n",
    "        peaks = peaks + 1  # Adjust for excluding first element\n",
    "        \n",
    "        # Calculate periodicity score from autocorrelation\n",
    "        if len(peaks) > 0:\n",
    "            autocorr_score = autocorr[peaks[0]] if peaks[0] < len(autocorr) else 0\n",
    "            spacing = np.mean(np.diff(x_data))\n",
    "            autocorr_period = peaks[0] * spacing\n",
    "        else:\n",
    "            autocorr_score = 0\n",
    "            autocorr_period = None\n",
    "        \n",
    "        # --- Method 2: FFT Analysis ---\n",
    "        n = len(y_detrended)\n",
    "        yf = fft(y_detrended)\n",
    "        spacing = np.mean(np.diff(x_data))\n",
    "        xf = fftfreq(n, spacing)[:n//2]\n",
    "        power = 2.0/n * np.abs(yf[:n//2])\n",
    "        \n",
    "        if len(power) > 1:\n",
    "            dominant_freq_idx = np.argmax(power[1:]) + 1\n",
    "            dominant_freq = xf[dominant_freq_idx]\n",
    "            fft_period = 1/dominant_freq if dominant_freq > 0 else None\n",
    "            \n",
    "            # FFT score: ratio of dominant peak to mean power\n",
    "            mean_power = np.mean(power[1:])\n",
    "            fft_score = power[dominant_freq_idx] / mean_power if mean_power > 0 else 0\n",
    "            fft_score = min(fft_score / 10, 1.0)  # Normalize to 0-1 range\n",
    "        else:\n",
    "            fft_period = None\n",
    "            fft_score = 0\n",
    "            dominant_freq = 0\n",
    "        \n",
    "        # --- Combined Score ---\n",
    "        combined_score = (autocorr_score + fft_score) / 2\n",
    "        \n",
    "        # Determine best period estimate\n",
    "        if autocorr_period and fft_period:\n",
    "            # Use autocorr period if both are available and similar\n",
    "            if abs(autocorr_period - fft_period) / max(autocorr_period, fft_period) < 0.3:\n",
    "                best_period = autocorr_period\n",
    "                period_confidence = \"high\"\n",
    "            else:\n",
    "                # Use the one with higher score\n",
    "                best_period = autocorr_period if autocorr_score > fft_score else fft_period\n",
    "                period_confidence = \"moderate\"\n",
    "        elif autocorr_period:\n",
    "            best_period = autocorr_period\n",
    "            period_confidence = \"moderate\"\n",
    "        elif fft_period:\n",
    "            best_period = fft_period\n",
    "            period_confidence = \"low\"\n",
    "        else:\n",
    "            best_period = None\n",
    "            period_confidence = \"none\"\n",
    "        \n",
    "        # Check rejection criteria\n",
    "        rejection_reason = None\n",
    "        if combined_score < min_score:\n",
    "            rejection_reason = f\"score = {combined_score:.3f} (too low)\"\n",
    "        elif best_period and best_period > max_period:\n",
    "            rejection_reason = f\"period = {best_period:.2f} (too large)\"\n",
    "        \n",
    "        if rejection_reason:\n",
    "            print(f\"\\nREJECTED v = {v}: {rejection_reason}\")\n",
    "            print(f\"  ({len(peaks)} autocorrelation peaks found)\")\n",
    "            rejected.append((v, combined_score, best_period))\n",
    "            continue\n",
    "        \n",
    "        # Package results\n",
    "        info_dict = {\n",
    "            'combined_score': combined_score,\n",
    "            'autocorr_score': autocorr_score,\n",
    "            'autocorr_period': autocorr_period,\n",
    "            'autocorr_peaks': len(peaks),\n",
    "            'fft_score': fft_score,\n",
    "            'fft_period': fft_period,\n",
    "            'dominant_frequency': dominant_freq,\n",
    "            'best_period': best_period,\n",
    "            'period_confidence': period_confidence\n",
    "        }\n",
    "        \n",
    "        results.append((v, combined_score, info_dict))\n",
    "        \n",
    "        print(f\"\\nAnalyzing v = {v}:\")\n",
    "        print(f\"  Autocorrelation peaks found: {len(peaks)}\")\n",
    "        print(f\"  Combined periodicity score = {combined_score:.6f}\")\n",
    "        print(f\"  Best period estimate = {best_period:.4f} (confidence: {period_confidence})\")\n",
    "        print(f\"  Autocorrelation: score = {autocorr_score:.4f}, period = {(autocorr_period if autocorr_period else 0):.4f}\")\n",
    "        print(f\"  FFT: score = {fft_score:.4f}, period = {(fft_period if fft_period else 0):.4f}\")\n",
    "        print(f\"  Dominant frequency = {dominant_freq:.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ANALYSIS COMPLETE: {len(results)} valid results, {len(rejected)} rejected\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "from sage.all import *\n",
    "precision_bits = 100\n",
    "CC = ComplexField(precision_bits)\n",
    "x = polygen(QQ)  # Can remain in preamble if all polynomials are in one variable\n",
    "matrix_list=[]\n",
    "charpol_list=[]\n",
    "roots_list=[]\n",
    "aar_list=[]\n",
    "centers_list=[]\n",
    "max_diameter_list=[]\n",
    "mins_list=[]\n",
    "log_mins_list=[]\n",
    "maxes_list=[]\n",
    "log_maxes_list=[]\n",
    "dets=[]\n",
    "tests=[]\n",
    "for n in range(1, 201):\n",
    "    print(\"----------------------------------------------------------------------------------------------------\")\n",
    "    deformed_j_list=j_list[:n]\n",
    "    inputs=[pair[1] for pair in deformed_j_list]\n",
    "    pl=P_matrix(inputs) ### DEFORMED\n",
    "    det=pl.det()\n",
    "    print((n,time.time()))\n",
    "    dets.append((n,det))\n",
    "    matrix_list+=[(n,pl)]\n",
    "    cp=pl.charpoly()\n",
    "    charpol_list+=[(n,cp)]\n",
    "    roots = cp.roots(ring=CC, multiplicities=False)       \n",
    "    roots_list+=[(n,roots)]\n",
    "    pairs = [(z.real(), z.imag()) for z in roots]\n",
    "    aar = [r.abs() for r in roots]\n",
    "    aar_list+=[(n,aar)]\n",
    "    # compute absolute value for each root (before any conversion)\n",
    "    if aar!=[]:\n",
    "        minn = min(aar)  \n",
    "        mins_list+=[(n,minn)]\n",
    "        mins_list.append((n,minn))\n",
    "        if minn>0:\n",
    "            log_minn=log(minn)\n",
    "            log_mins_list.append((n,log_minn))\n",
    "        maxx = max(aar)  \n",
    "        maxes_list.append((n,maxx))\n",
    "        if maxx>0:\n",
    "            log_maxx=log(maxx)\n",
    "            log_maxes_list.append((n,log_maxx))\n",
    "    if n%50==0:\n",
    "        p = list_plot(mins_list, plotjoined=True, axes_labels=['', ''])\n",
    "        print(\"MINIMUM MODULI\")\n",
    "        p.show()\n",
    "        p = list_plot(log_mins_list, plotjoined=True, axes_labels=['', ''])\n",
    "        print(\"LOGS MINIMUM MODULI\")\n",
    "        p.show()\n",
    "        mml=[pair[1] for pair in log_mins_list]\n",
    "        print(\"minimum logarithm of minimum modulus:\",min(mml))\n",
    "        p = list_plot(maxes_list, plotjoined=True, axes_labels=['', ''])\n",
    "        print(\"MAXIMUM MODULI\")\n",
    "        p.show()\n",
    "    results = periodic_behavior_score(mins_list, min_score=0.3, max_period=100)\n",
    "print(\"tests:\")\n",
    "print(tests)\n",
    "with open('/Users/barrybrent/data/run5nov25no3.txt', 'wb') as wfile:\n",
    "    pickle.dump(roots_list, wfile) #output snipped\n",
    "\n",
    "with open('/Users/barrybrent/data/run5nov25no4.txt', 'wb') as wfile:\n",
    "    pickle.dump(charpol_list, wfile) #output snipped\n",
    "\n",
    "with open('/Users/barrybrent/data/run5nov25no5.txt', 'wb') as wfile:\n",
    "    pickle.dump(dets, wfile) #output snipped\n",
    "\n",
    "with open('/Users/barrybrent/data/run5nov25no6.txt', 'wb') as wfile:\n",
    "    pickle.dump(matrix_list, wfile) #output snipped\n",
    "\n",
    "from sage.plot.colors import rainbow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_values = [n for n, roots in roots_list]\n",
    "n_min, n_max = min(n_values), max(n_values)\n",
    "colors = rainbow(len(n_values))\n",
    "\n",
    "# Collect all points with their n values for matplotlib\n",
    "all_points = []\n",
    "all_n_values = []\n",
    "for n, roots in roots_list:\n",
    "    for z in roots:\n",
    "        all_points.append((float(z.real()), float(z.imag())))\n",
    "        all_n_values.append(n)\n",
    "\n",
    "# Use matplotlib for better color mapping\n",
    "real_parts = [p[0] for p in all_points]\n",
    "imag_parts = [p[1] for p in all_points]\n",
    "\n",
    "plt.scatter(real_parts, imag_parts, c=all_n_values, cmap='rainbow', s=1)\n",
    "plt.colorbar(label='n')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Imaginary')\n",
    "plt.title('Roots colored by n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f272302e-9f95-478e-9d76-2215add7f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairs_to_10:\n",
      "[(1, 2), (2, -20), (3, -280), (4, 112876), (5, 13617464), (6, 1354789648), (7, 35774536160), (8, -20152100078000), (9, -6503743774819936), (10, -1142231947341552704)]\n",
      "\n",
      "values:\n",
      "[2, -20, -280, 112876, 13617464, 1354789648, 35774536160, -20152100078000, -6503743774819936, -1142231947341552704]\n",
      "\n",
      "h_values:\n",
      "[2, -10, -140/3, 28219/6, 1702183/15, 84674353/45, 447181702/63, -251901250975/504, -203241992963123/11340, -2549624882458823/8100]\n",
      "\n",
      "reduced:\n",
      "[1, -5, -70/3, 28219/12, 1702183/30, 84674353/90, 223590851/63, -251901250975/1008, -203241992963123/22680, -2549624882458823/16200]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/barrybrent/data/run5nov25no5.txt', 'rb') as rfile:\n",
    "    dets = pickle.load(rfile)\n",
    "\n",
    "\n",
    "pairs_to_10=dets[:10]\n",
    "print(\"pairs_to_10:\")\n",
    "print(pairs_to_10)\n",
    "print()\n",
    "values=[pair[1]for pair in pairs_to_10]\n",
    "print(\"values:\")\n",
    "print(values)\n",
    "h_values=[pair[1]/factorial(pair[0]) for pair in pairs_to_10]\n",
    "print()\n",
    "print(\"h_values:\")\n",
    "print(h_values)\n",
    "print()\n",
    "print(\"reduced:\")\n",
    "reduced=[x/2 for x in h_values]\n",
    "print(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcce5b5-bde6-4318-b568-898e67eaff1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.8",
   "language": "sage",
   "name": "sagemath-10.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
